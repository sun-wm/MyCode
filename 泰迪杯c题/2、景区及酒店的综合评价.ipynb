{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4ce8f06-5ced-45fd-81be-c9c7fe50e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import jieba\n",
    "from collections import Counter\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "from tqdm import tqdm \n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20926798-d7af-4baa-bd1a-ec47b7a42681",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pd.read_excel(r\"./附件1/酒店评论.xlsx\",engine='openpyxl')    \n",
    "\n",
    "label = pd.read_excel(r\"./附件2/酒店评分.xlsx\",engine='openpyxl')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5133ce87-0f11-4b1e-ac9b-5f33e9b8d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def participle(stopwords,is_filter=True,):\n",
    "    all_words = []\n",
    "    for idx,line in enumerate(content['评论内容']):\n",
    "        if is_filter:         \n",
    "            line = filter_punc(line)\n",
    "       \n",
    "        words = jieba.lcut(line)\n",
    "        if len(words)>0:\n",
    "            all_words += words\n",
    "            \n",
    "    dictions = {}\n",
    "    cnt = Counter(all_words)\n",
    "    for word,freq in cnt.items():\n",
    "        if freq>1:\n",
    "            if word not in stopwords:\n",
    "                dictions[word] = [len(dictions),freq]\n",
    "    return dictions\n",
    "\n",
    "# 过去标点符号\n",
    "def filter_punc(sentence):\n",
    "    sentence = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\'“”《》?“]+|[+——！，。？、~@#￥%……&*（）：]+\", \"\", sentence)\n",
    "    return(sentence)\n",
    "# 去除停用词\n",
    "\n",
    "def move_stopwords(sentence_list, stopwords_list):\n",
    "    # 去停用词\n",
    "    out_list = []\n",
    "    for word in sentence_list:\n",
    "        if word not in stopwords_list:\n",
    "#             if not remove_digits(word):\n",
    "#                 continue\n",
    "            if word != '\\t':\n",
    "                out_list.append(word)\n",
    "    return out_list\n",
    "\n",
    "#使用停用词\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "#得到分词后的词句，和对应的标签\n",
    "def participle1(name,stopwords,is_filter=True):\n",
    "    sentence = []\n",
    "    labels=[]\n",
    "    \n",
    "    for j,i in enumerate(name):\n",
    "        data = content.loc[content['酒店名称']==i]\n",
    "        a=[label['总得分'][j],label['服务得分'][j],label['位置得分'][j],label['设施得分'][j],label['卫生得分'][j],label['性价比得分'][j]]\n",
    "        for idx,line in enumerate(data['评论内容']):\n",
    "            if is_filter:         \n",
    "                line = filter_punc(line)\n",
    "            \n",
    "            words = jieba.lcut(line)\n",
    "            words = move_stopwords(words,stopwords)\n",
    "            if len(words)>0:\n",
    "                sentence.append(words)\n",
    "                labels.append(a) \n",
    "        break\n",
    "    return sentence,labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28914cf5-6917-4d35-b94c-696bdf4e96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "stopwords = stopwordslist('hit_stopwords.txt')\n",
    "for i in list(content.groupby('酒店名称')):\n",
    "    names.append(i[0])  \n",
    "\n",
    "\n",
    "diction = participle(stopwords,True)\n",
    "sentence,labels = participle1(names,stopwords,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6de60e2-0e51-469e-aebf-354cd18fa45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据单词返还单词的编码\n",
    "def word2index(word,diction):\n",
    "    if word in diction:\n",
    "        value=diction[word][0]\n",
    "    else:\n",
    "        value=-1\n",
    "    return(value)\n",
    "\n",
    "# 更具编码获取对应的单词\n",
    "def index2word(index,diction):\n",
    "    for w,v in diction.items():\n",
    "        if v[0]==index:\n",
    "            return(w)\n",
    "    return(None)\n",
    "# 输入一个句子和相应的词典，得到这个句子的向量化表示\n",
    "# 向量的尺寸为词典中词汇的个数，i位置上面的数值为第i个单词在sentence中出现的频率\n",
    "def sentence2vec(sentence,dictionary):\n",
    "    vector = np.zeros(len(dictionary))\n",
    "    for l in sentence:\n",
    "        vector[l]+=1\n",
    "#     return vector\n",
    "    return ((1.0*vector)/len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2644ec4b-d161-4fd4-ba14-76761981327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[]  #数据集\n",
    "sentences=[] #原始句子\n",
    "labels1=[]\n",
    "j=0\n",
    "for i in sentence:\n",
    "    new_sentence=[]\n",
    "    j+=1\n",
    "    for l in i:\n",
    "        if l in diction:\n",
    "            new_sentence.append(word2index(l,diction))\n",
    "    if len(new_sentence)!=0:\n",
    "        dataset.append(sentence2vec(new_sentence,diction))\n",
    "        labels1.append(labels[j-1])\n",
    "    sentences.append(i)\n",
    "labels=labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d80d143-81dd-4e21-b26a-99d7528f167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.random.permutation(len(dataset))\n",
    "dataset = [dataset[i] for i in indices]\n",
    "labels = [labels[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed9836b4-a6e0-4515-ae03-842dede22b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = len(dataset) // 10\n",
    "# 训练集\n",
    "train_data = dataset[2*test_size :]\n",
    "train_label=labels[2*test_size :]\n",
    "# 检测集\n",
    "valid_data = dataset[: test_size]\n",
    "valid_label = labels[: test_size]\n",
    "# 测试集\n",
    "test_data = dataset[test_size : 2*test_size]\n",
    "test_label = labels[test_size : 2*test_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38ee2144-5fdf-4d96-90c9-57687da9e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，除了初始化隐含但愿部分，所有代码基本与SimpleRNN相同\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # 一个embedding层\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # 隐含层内部的相互链接\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, input,hidden):\n",
    "        # 先进行embedding层的计算，它可以把一个\n",
    "        # x的尺寸：batch_size, len_seq, input_size\n",
    "        x = self.embedding(input)\n",
    "        # x的尺寸：batch_size, len_seq, hidden_size\n",
    "        # 从输入到隐含层的计算\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        # hidden: (layer_size, batch_size, hidden_size),(layer_size, batch_size,hidden_size)\n",
    "        output = output[:,-1,:]\n",
    "        # output的尺寸：batch_size, hidden_size\n",
    "        output = self.fc(output)\n",
    "        # output的尺寸：batch_size, output_size\n",
    "        # softmax函数\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self,n):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = t.zeros(self.num_layers, n, self.hidden_size)\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = t.zeros(self.num_layers, n, self.hidden_size)\n",
    "        return (hidden, cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2667b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义的计算一组数据分类准确度的函数\n",
    "def rightness(predictions,labels):\n",
    "    \n",
    "    j=0\n",
    "    for f in range(len(labels)):\n",
    "        a=np.round(predictions[0][f].data,1).eq(np.round(labels[f].data,1))\n",
    "        if a:\n",
    "            j+=1\n",
    "    return j,len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b72b83-50ad-49c1-9e00-bbcd070bae15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失： 20.950720，校验损失：20.935438，校验准确度：0.00\n",
      "第1轮，训练损失： 13.331545，校验损失：12.167562，校验准确度：0.00\n",
      "第2轮，训练损失： 6.915923，校验损失：8.114012，校验准确度：0.31\n",
      "第3轮，训练损失： 4.613368，校验损失：6.086873，校验准确度：0.32\n",
      "第4轮，训练损失： 3.461601，校验损失：4.870481，校验准确度：0.33\n",
      "第5轮，训练损失： 2.770335，校验损失：4.059473，校验准确度：0.35\n",
      "第6轮，训练损失： 2.309373，校验损失：3.480120，校验准确度：0.36\n",
      "第7轮，训练损失： 1.980035，校验损失：3.045557，校验准确度：0.43\n",
      "第8轮，训练损失： 1.732974，校验损失：2.707525，校验准确度：0.44\n",
      "第9轮，训练损失： 1.540772，校验损失：2.437068，校验准确度：0.49\n",
      "第10轮，训练损失： 1.386978，校验损失：2.215760，校验准确度：0.53\n",
      "第11轮，训练损失： 1.261120，校验损失：2.031315，校验准确度：0.56\n",
      "第12轮，训练损失： 1.156217，校验损失：1.875230，校验准确度：0.59\n",
      "第13轮，训练损失： 1.067435，校验损失：1.741428，校验准确度：0.62\n",
      "第14轮，训练损失： 0.991322，校验损失：1.625453，校验准确度：0.66\n",
      "第15轮，训练损失： 0.925346，校验损失：1.523966，校验准确度：0.69\n",
      "第16轮，训练损失： 0.867606，校验损失：1.434409，校验准确度：0.72\n",
      "第17轮，训练损失： 0.816652，校验损失：1.354796，校验准确度：0.77\n",
      "第18轮，训练损失： 0.771351，校验损失：1.283557，校验准确度：0.78\n",
      "第19轮，训练损失： 0.730814，校验损失：1.219437，校验准确度：0.79\n",
      "第20轮，训练损失： 0.694325，校验损失：1.161418，校验准确度：0.84\n",
      "第21轮，训练损失： 0.661307，校验损失：1.108670，校验准确度：0.85\n",
      "第22轮，训练损失： 0.631287，校验损失：1.060506，校验准确度：0.86\n",
      "第23轮，训练损失： 0.603874，校验损失：1.016352，校验准确度：0.91\n",
      "第24轮，训练损失： 0.578743，校验损失：0.975727，校验准确度：0.94\n"
     ]
    }
   ],
   "source": [
    "lstm = SimpleLSTM(input_size = len(diction), hidden_size = 10, output_size = 6, num_layers = 1)\n",
    "\n",
    "\n",
    "# 损失函数为交叉熵\n",
    "\n",
    "MSE = t.nn.MSELoss()\n",
    "optimizer = optim.SGD(lstm.parameters(),lr=0.001)\n",
    "records=[]\n",
    "\n",
    "losses=[]\n",
    "val_losses=[]\n",
    "\n",
    "for epoch in tqdm(range(10)):\n",
    "    for i,data in enumerate(zip(train_data,train_label)):\n",
    "\n",
    "        x = t.tensor(data[0], dtype = t.long).unsqueeze(0)\n",
    "        # x尺寸：batch_size = 1, time_steps = 1, data_dimension = 1\n",
    "        y = t.tensor(data[1], dtype = t.float)\n",
    "        \n",
    "        hidden = lstm.initHidden(len(x))\n",
    "        optimizer.zero_grad()\n",
    "        predict,hidden=lstm(x,hidden)\n",
    "        loss = MSE(predict[0],y)\n",
    "        losses.append(loss.data.numpy())\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%100==0:\n",
    "\n",
    "            rights=[]\n",
    "            \n",
    "            for j,val in enumerate(zip(valid_data,valid_label)):\n",
    "\n",
    "                x = t.tensor(val[0], dtype = t.long).unsqueeze(0)\n",
    "                # x尺寸：batch_size = 1, time_steps = 1, data_dimension = 1\n",
    "                y = t.tensor(val[1], dtype = t.float)\n",
    "                hidden = lstm.initHidden(len(x))\n",
    "                predict,hidden=lstm(x,hidden)\n",
    "                right = rightness(predict,y)\n",
    "                rights.append(right)\n",
    "                loss = MSE(predict,y)\n",
    "                val_losses.append(loss.data.numpy())\n",
    "            \n",
    "            right_ratio=1.0*np.sum([i[0] for i in rights])/np.sum([i[1] for i in rights])\n",
    "            print('第{}轮，训练损失： {:.6f}，校验损失：{:.6f}，校验准确度：{:.2f}'.format(epoch,np.mean(losses),np.mean(val_losses),right_ratio))\n",
    "            records.append([np.mean(losses),np.mean(val_losses),right_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87e31963-b36f-4c54-a139-833d6618b9be",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7000, 4.8000, 4.8000, 4.6000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.7000, 4.8000, 4.8000, 4.6000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.9000, 4.8000, 4.8000, 4.8000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.7000, 4.8000, 4.8000, 4.6000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "tensor([[4.8000, 4.8000, 4.8000, 4.7000, 4.8000, 4.0000]])\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(zip(test_data,test_label)):\n",
    "    x,y=data\n",
    "    x=Variable(t.FloatTensor(x).view(1,-1))\n",
    "    y=Variable(t.FloatTensor(np.array([y])))\n",
    "    predict = model(x)\n",
    "    right = rightness(predict,y)\n",
    "    np.round(predict.data,1)\n",
    "    print(np.round(predict.data,1))\n",
    "    print(y)\n",
    "    print('----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46aab127-cf22-47cb-a67d-3de089539baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a3d4d63a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = [i[0] for i in records]\n",
    "b = [i[1] for i in records]\n",
    "c = [i[2] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.plot(b, label = 'Valid Loss')\n",
    "plt.plot(c, label = 'Valid Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35c1c8e7-6e77-4ba3-aa15-22ae8851dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(model, 'model2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d56fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
