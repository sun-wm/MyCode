{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e0905a-0c6a-4f6a-ae2c-a60b44f27029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch用的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.utils.data as DataSet\n",
    "\n",
    "\n",
    "#绘图、计算用的程序包\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import numpy as np\n",
    "#将图形直接显示出来\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 导入程序所需要的程序包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42109697-764e-4b8b-886d-fd9e18112724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('10.xls',sheet_name=\"监测数据报表\",skiprows=2,parse_dates=['监测时间'])  #读取excel表\n",
    "data.drop(['备注','污水排口监控点排放量(吨)','Unnamed: 6','Unnamed: 7','Unnamed: 8','Unnamed: 9'],axis=1,inplace=True)   #删除NaN列\n",
    "data.drop(0,inplace=True)\n",
    "data = data.set_index(['监测时间'])\n",
    "data.drop(index=(data.loc[(data['PH值']=='停运')].index),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c27e80-8f2a-497e-aeec-f44f626c01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示函数\n",
    "#解决中文显示问题\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "def plot_prediction(test_result,predict_result):\n",
    "    \"\"\"\n",
    "    test_result:真实值\n",
    "    predict_result:预测值\n",
    "    \"\"\"\n",
    "    plt.plot(test_result,color ='red',label = 'water element true value')\n",
    "    plt.plot(predict_result,color ='blue',label = 'water element predicted value')\n",
    "    plt.title(\"water element values\")\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"element values\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73d0bf-6ee4-4759-868f-b94fc167059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['化学需氧量(COD)(毫克/升)'] = data['化学需氧量(COD)(毫克/升)'].astype('float')\n",
    "data['氨氮(毫克/升)'] = data['氨氮(毫克/升)'].astype('float')\n",
    "data['PH值'] = data['PH值'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516d923-82be-4ed0-a96d-188a6ad9fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制训练集测试集数据\n",
    "data['PH值'][:'2020-06'].plot(figsize=(16,4),legend = True)\n",
    "data['PH值']['2020-07':].plot(figsize=(16,4),legend = True)\n",
    "data['化学需氧量(COD)(毫克/升)'][:'2020-06'].plot(figsize=(16,4),legend = True)\n",
    "data['化学需氧量(COD)(毫克/升)']['2020-07':].plot(figsize=(16,4),legend = True)\n",
    "data['氨氮(毫克/升)'][:'2020-06'].plot(figsize=(16,4),legend = True)\n",
    "data['氨氮(毫克/升)']['2020-07':].plot(figsize=(16,4),legend = True)\n",
    "\n",
    "plt.title(\"water element values\")\n",
    "\n",
    "# plt.legend(\"train\",\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac7fa7-7d67-4b94-a0d7-1d8a3b8146a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #归一化\n",
    "scaler =  StandardScaler() # 然后生成一个标准化对象\n",
    "train_set_scaled = scaler.fit_transform(data)  #然后对data数据进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51ba7d-0c52-4c26-ac13-cf3013d11a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练集和校验集\n",
    "X = []\n",
    "Y = []\n",
    "# 首先，按照预测的模式，我们将原始数据生成一对一对的训练数据\n",
    "n_prev = 7*24 # 滑动窗口长度为30\n",
    "\n",
    "# 对数据中的所有数据进行循环\n",
    "for i in range(len(train_set_scaled)-n_prev):\n",
    "    # 往后取n_prev个note作为输入属性\n",
    "    x = train_set_scaled[i:i+n_prev]\n",
    "    # 将第n_prev+1个note（编码前）作为目标属性\n",
    "    y = train_set_scaled[i+n_prev]\n",
    "    \n",
    "    # 将X和Y加入到数据集中\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "\n",
    "\n",
    "# 对所有数据顺序打乱重排\n",
    "idx = np.random.permutation(range(len(X)))\n",
    "# 形成训练与校验数据集列表\n",
    "X = [X[i] for i in idx]\n",
    "Y = [Y[i] for i in idx]\n",
    "\n",
    "# 从中切分1/10的数据出来放入校验集\n",
    "validX = X[: len(X) // 10]\n",
    "X = X[len(X) // 10 :]\n",
    "validY = Y[: len(Y) // 10]\n",
    "Y = Y[len(Y) // 10 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6160fdb2-f4ba-4ec9-81e6-7da12cd6f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 测试数据集的加载器，自动将数据切分成批，顺序随机打乱\n",
    "test_data=torch.utils.data.DataLoader(dataset=validX,\n",
    "                         batch_size=24,\n",
    "                         shuffle=False)\n",
    "\n",
    "test_label=torch.utils.data.DataLoader(dataset=validY,\n",
    "                         batch_size=24,\n",
    "                         shuffle=False)\n",
    "\n",
    "\n",
    "# 训练数据集的加载器，自动将数据切分成批，顺序随机打乱\n",
    "train_data=torch.utils.data.DataLoader(dataset=X,\n",
    "                         batch_size=24,\n",
    "                         shuffle=False)\n",
    "\n",
    "# 训练数据集的加载器，自动将数据切分成批，顺序随机打乱\n",
    "train_label=torch.utils.data.DataLoader(dataset=Y,\n",
    "                         batch_size=24,\n",
    "                         shuffle=False)\n",
    "\n",
    "\n",
    "# 形成训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc5f20-25a9-4509-8d83-3fb3f6b62840",
   "metadata": {},
   "source": [
    "### input_dim = 3   #输入维度\n",
    "### hidden_dim = 128 #隐层的维度\n",
    "### layer_dim = 1   #多少层隐层\n",
    "### output_dim = 3   #输出维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08999e-76d3-42c9-8862-62864dae91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers=2):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        # 一层LSTM单元\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, n_layers, batch_first = True)\n",
    "        # 一个Dropout部件，以0.2的概率Dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        # 一个全链接层\n",
    "        self.fc = nn.Linear(hidden_size, out_size)\n",
    "        # 对数Softmax层\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        # 神经网络的每一步运算\n",
    "\n",
    "        hhh1 = hidden[0] #读如隐含层的初始信息\n",
    "        # 完成一步LSTM运算\n",
    "        # input的尺寸为： batch_size ,day(1), input_size\n",
    "        output, hhh1 = self.lstm(input, hhh1) #input:batchsize*timestep*3\n",
    "        # 对神经元输出的结果进行dropout\n",
    "        output = self.dropout(output)\n",
    "        # 取出最后一个时刻的隐含层输出值\n",
    "        # output的尺寸为：batch_size, time_step, hidden_size\n",
    "        output = output[:, -1, ...]\n",
    "        # 此时，output的尺寸为：batch_size, hidden_size\n",
    "        # 喂入一个全链接层\n",
    "        out = self.fc(output)\n",
    "        # out的尺寸为：batch_size, output_size\n",
    "\n",
    "        # 将out的最后一个维度分割成三份x, y, z分别对应对note，velocity以及time的预测\n",
    "        \n",
    "      \n",
    "        return out\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 对隐含层单元变量全部初始化为0\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        out = []\n",
    "        hidden1=torch.zeros(self.n_layers, batch_size, self.hidden_size).requires_grad_(True)\n",
    "        cell1=torch.zeros(self.n_layers, batch_size, self.hidden_size).requires_grad_(True)\n",
    "        out.append((hidden1, cell1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfd31a-d2fd-40cb-9086-94ae3c3d0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个LSTM，其中输入输出层的单元个数取决于每个变量的类型取值范围\n",
    "lstm = LSTMNetwork(3,128,3)\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "records = []\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    # 开始遍历加载器中的数据\n",
    "\n",
    "    for batch, data in enumerate(zip(train_data,train_label)):\n",
    "        init_hidden = lstm.initHidden(len(data[0]))\n",
    "        x=Variable(torch.FloatTensor(data[0])).requires_grad_(True)\n",
    "#         x=Variable(torch.FloatTensor(data[0])).requires_grad_(True).unsqueeze(0)\n",
    "#         x=Variable(torch.FloatTensor(data[0])).requires_grad_(True).view(24,30,3)\n",
    "        y=Variable(torch.FloatTensor(data[1]))\n",
    "        # batch为数字，表示已经进行了第几个batch了\n",
    "        # data为一个二元组，分别存储了一条数据记录的输入和标签\n",
    "        # 每个数据的第一个维度都是batch_size = 30的数组\n",
    "        \n",
    "        lstm.train() # 标志LSTM当前处于训练阶段，Dropout开始起作用\n",
    "#         init_hidden = lstm.initHidden(24) # 初始化LSTM的隐单元变量\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        outputs = lstm(x, init_hidden) #喂入LSTM，产生输出outputs\n",
    "\n",
    "        Mse = nn.MSELoss()\n",
    "        loss = Mse(outputs,y) #代入损失函数并产生loss\n",
    "#         print(loss.data.numpy())\n",
    "        train_loss.append(loss.data.numpy()) # 记录loss\n",
    "        loss.backward() #反向传播\n",
    "        optimizer.step() #梯度更新\n",
    "    if epoch % 2==0:\n",
    "        #在校验集上跑一遍，并计算在校验集上的分类准确率\n",
    "        test_loss = []\n",
    "        lstm.eval() #将模型标志为测试状态，关闭dropout的作用\n",
    "        rights = []\n",
    "        # 遍历加载器加载进来的每一个元素\n",
    "        \n",
    "        for batch, data in enumerate(zip(test_data,test_label)):\n",
    "#             init_hidden = lstm.initHidden(24)\n",
    "            init_hidden = lstm.initHidden(len(data[0]))\n",
    "            #完成LSTM的计算\n",
    "            x=Variable(torch.FloatTensor(data[0])).requires_grad_(True)\n",
    "            y=Variable(torch.FloatTensor(data[1]))\n",
    "            outputs = lstm(x, init_hidden)\n",
    "            #outputs: (batch_size*89, batch_size*128, batch_size*11)\n",
    "            #Loss=nn.L1Loss(size_average=True)\n",
    "            Mse = nn.MSELoss()\n",
    "            loss = Mse(outputs,y) #代入损失函数并产生loss #代入损失函数并产生lo\n",
    "            test_loss.append(loss.data.numpy())\n",
    "            #计算每个指标的分类准确度\n",
    "            \n",
    "            right1 = np.round(outputs[:,0].data,4).eq(np.round(y[:,0].data,4)).sum()\n",
    "            right2 = np.round(outputs[:,1].data,4).eq(np.round(y[:,1].data,4)).sum()\n",
    "            right3 = np.round(outputs[:,2].data,4).eq(np.round(y[:,2].data,4)).sum()\n",
    "            rights=((right1 + right2 + right3) * 1.0 )/ (3*len(outputs))\n",
    "        # 打印结果\n",
    "        print('第{}轮, 训练Loss:{:.2f}, 校验Loss:{:.2f}, 校验准确度:{:.2f}'.format(epoch, \n",
    "                                                                    np.mean(train_loss),\n",
    "                                                                    np.mean(test_loss),\n",
    "                                                                    rights\n",
    "                                                               ))\n",
    "        records.append([np.mean(train_loss), np.mean(test_loss), rights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2035b-46b0-4a71-a2e2-f2ef0a194f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm,'minst_conv_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1b6ba-f8f3-4ad6-bf0b-ae9561fe999c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42da82-b154-4baa-9e32-5c3bccff270f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be5bf5-3ca0-400e-aa54-cf62ea016f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c5e5a-93fc-4f01-8d0c-49d0fbf80b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12e0e5-7af5-4e36-94c9-b30cf1421019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be1537c-8146-4a19-83dd-2310edf73547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb8800-b1a2-4499-b125-1386d48aa971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
